{"pageProps":{"id":"python_logging_with_multi-process","postData":{"id":"python_logging_with_multi-process","contentHtml":"<h1>python logging with multi process</h1>\n<h2>배경지식</h2>\n<ul>\n<li>python은 정확히 말하자면 싱글 스레드 언어가 아니다. 다만 GIL 때문에 스레드를 활용하여 효율을 높이는 것이 어려운 편이다.\n<ul>\n<li>GIL은 global interpreter lock를 말하는 것으로 python이 채용한 스레드 문제를 해결하는 방식이다.</li>\n<li>GIL은 멀티 스레드가 동시에 병렬로 진행되는 것을 막고, 한 스레드가 동작할 때는 다른 스레드를 멈추게 한다.(특정 예외가 있긴 한데, 대부분의 경우에는 lock이 걸려 병렬 진행하는 것만큼 효율이 안 나온다)</li>\n</ul>\n</li>\n<li>따라서 서버 성능을 이끌어내는 방법으로 멀티 쓰레드보다는 멀티 프로세스쪽으로 많이 접근하는 편이다.</li>\n<li>log rotate라는 것은 기존의 로그 파일을 닫고 이름을 변경한 뒤, 새 로그 파일을 만들어 새롭게 로그를 적는 것을 말한다.\n<ul>\n<li>대부분의 메이저 서버 프로그램들은 위와 같은 기능을 자체적으로 가지고 있거나, 최소한 위와 같은 행위를 인식할 수 있는 api를 만들어둔다.</li>\n<li>USR1이 대표적인 api이다.</li>\n</ul>\n</li>\n</ul>\n<h2>문제</h2>\n<ul>\n<li>python 서버 운영을 하던 중 logging에서 logrotate하는 시간대에 로그가 누락되는 문제 발견\n<ul>\n<li>기존 python 서버에서는 log를 copytruncate하는 방식으로 관리해왔는데, 이 방식을 사용할 경우 filebeat에서 변경을 감지하지 못해서 누락되는 거였다.</li>\n<li>copytruncate는 기존 로그 파일은 그대로 둔 채로, 내용만 복사하여 옮긴 뒤 원본에 내용을 지우는 방식이다.</li>\n</ul>\n</li>\n<li>이를 고치기 위해 logging 및 log rotate 정책을 변경해야될 필요성이 생김</li>\n</ul>\n<h2>해결</h2>\n<h3>python logging</h3>\n<ul>\n<li>기존의 python 서버는 파이썬에서 제공하는 기본 logging 라이브러리를 사용</li>\n<li>logging 라이브러리에 대한 공식 문서가 나와 있긴 한데, 단순 python 실행에 대한 설명만 있음(https://docs.python.org/ko/3/howto/logging.html)</li>\n<li>대부분의 파이썬 서버 환경인 multi processs 환경에서 logging과 관련하여 생길 수 있는 문제에 대해서는 잘 설명되어 있는 영문 문서를 찾음(https://www.packetmischief.ca/2017/10/25/3-ways-to-fail-at-logging-with-flask/)</li>\n</ul>\n<h3>python logging with multi process</h3>\n<ul>\n<li>\n<p>여기서부터의 내용은 기본적으로 위 영문 문서의 요약본임</p>\n</li>\n<li>\n<p>python logging 라이브러리는 기본적으로 하나의 프로세스를 가정하여 만들어져 있기 때문에, 하나의 파일에 하나의 프로세스가 적는 것을 기대함</p>\n</li>\n<li>\n<p>하지만 위에 언급되어 있듯이, python server는 대체로 multi process 환경에서 돌아가기 때문에, python logging 라이브러리를 쓰게 될 경우 여러 프로세스가 하나의 파일에 접근하는 상황이 만들어짐</p>\n</li>\n<li>\n<p>RotateFileHandler의 경우</p>\n<ul>\n<li>RotateFileHandler는 적고 있는 로그 파일의 크기가 일정 이상이 되면 rotate하는 방식이다.</li>\n<li>프로세스가 하나일 때는 합리적인 방식이지만, 프로세스가 여러 개가 되면 최초로 rotate하는 프로세스는 파일을 바꾸고 새 파일에 적절히 로그를 넣지만, 다른 프로세스는 이를 감지하지 못할 수 있다.</li>\n<li>그렇게 되면 다른 프로세스들은 서버 시작시에 연 기존 로그 파일에 계속 로그를 써넣으면서도, 이름이 변경되었기 때문에 rotate를 해야된다는 사실을 감지하지 못해 엉뚱한 곳에 로그가 쌓일 수도 있게 된다.</li>\n</ul>\n</li>\n<li>\n<p>TimedRotateHandler의 경우</p>\n<ul>\n<li>TimedRotateHandler는 특정 시간 혹은 서비스가 시작된 후로 경과된 시간을 기반으로 rotate하는 방식이다.</li>\n<li>위와 마찬가지로 최초의 프로세스는 성공적으로 rotate를 하겠지만, RotateFileHandler와 같이 다른 프로세스들은 기존 파일의 변화를 인식하지 못하고 그대로 써넣을 수 있다.</li>\n<li>게다가 rotate가 제대로 되지 않을 가능성이 있다.\n<ul>\n<li>이에 대해서 조금 더 찾아봤는데, TimedRotateHandler가 logging 객체가 생성된 후로 지난 시간을 기준으로 작동해서 logging 객체가 수시로 생성 및 파기될 경우(GC) 정상적으로 작동하기 어렵다는 말이 있었다.(확인되지 않음)</li>\n<li>혹은 여러 프로세스가 동시에 한 파일에 접근하여 생성 혹은 변경을 하려고 하는 경우가 생겨 작동을 안 하는 것일 수도 있다.(확인되지 않음)</li>\n</ul>\n</li>\n<li>그리고 추가로 위와 같은 충돌까지는 아니더라도 다른 프로세스에서 작업 중인 파일에 로그를 적으려들면, 권한의 문제로 로그가 적히지 않을 수 있으니 로그가 유실될 가능성도 있다.</li>\n<li>영문 글에서 소개된 3가지 방식 중 가장 안 좋은 방식으로 소개되고 있다.</li>\n</ul>\n</li>\n<li>\n<p>WatchedFileHandler의 경우</p>\n<ul>\n<li>WatchedFileHandler는 로그를 특정 이름의 파일에 계속 적다가, 대상 파일이 변경된 것을 감지하면, 다시 특정 이름의 파일을 다시 열어서 쓰는 방식이다.</li>\n<li>linux체제마다 다르겠지만, os에서 제공하는 log rotate 툴과 함께 사용할 것을 권장한다.\n<ul>\n<li>window는 그런거 없기 때문에, window에서의 사용은 권장하지 않는다.</li>\n</ul>\n</li>\n<li>log rotate가 한창 진행되고 있는 도중에는 최초의 프로세스 외에는 그 사실을 모르므로, 일부의 로그가 기대된 신규 로그에 작성되지 않고 기존 로그에 작성될 가능성이 있다.\n<ul>\n<li>다만 로그가 유실되는 것은 아니고, 잘못 적힐 수 있는 log rotate되는 시간도 짧은 편이다.</li>\n</ul>\n</li>\n<li>영문 글에서 소개된 3가지 방식 중 그나마 나은 방식으로 소개되고 있다.</li>\n</ul>\n</li>\n</ul>\n<h3>결론</h3>\n<ul>\n<li>결국 영문 글에서 추천하는 것은, logging 및 log rotate를 python 내부나 os의 툴을 사용하여 하지 말고, 외부의 logging을 모니터링할 수 있는 별도의 대책을 마련하라는 것이다.\n<ul>\n<li>영문 글에서는 Sentry를 예시로 들었다.</li>\n</ul>\n</li>\n<li>차선책으로는 os의 log rotate 툴과 WatchedFileHandler를 쓰는 것을 권했다.\n<ul>\n<li>Sentry나 추가 모니터링 툴은 결국 회사의 결정이 필요한 해결책이다 보니, 필자도 차선책을 택했다.</li>\n</ul>\n</li>\n</ul>\n","title":"Python logging with multi process","date":"2023-01-03","tags":["python","logging","flask","multi process"]}},"__N_SSG":true}